> 原文：https://drive.google.com/file/d/1C-HvqgxM7dj4G2kCQLnuMXi1fTpXRdpx/view
> 前作： https://drive.google.com/file/d/1W8EnoPXRLTQesfjvb-b3Zj-dnBf1f--n/view
> https://drive.google.com/file/d/1GVPdwEh48bErTNdhxD0vqxPAifSx1I6Y/view


# Introduction to  Agents

## Introduction to AI Agents


AI 智能体可以被定义为模型、工具、编排层和运行时服务的组合，它利用语言模型在一个循环中完成目标。这四个元素构成了任何自主系统的基本架构。

* 模型（“大脑”）：核心语言模型（LM）或基础模型，作为代理的中心推理引擎，用于处理信息、评估选项和做出决策。模型的类型（通用型、微调型或多模态）决定了代理的认知能力。代理系统是输入上下文窗口的最终策展者

* 工具（“手”）：这些机制将代理的推理与外部世界连接起来，使其能够执行超出文本生成范围的操作。它们包括 API 扩展、代码函数以及数据存储（如数据库或向量存储），用于获取实时、事实性信息。一个代理系统允许语言模型规划使用哪些工具，执行工具，并将工具结果放入下一个语言模型调用的输入上下文窗口中。

* 协调层（"神经系统"）：管理代理操作循环的治理过程。它处理规划、记忆（状态）和推理策略执行。该层使用提示框架和推理技术（如Chain-of-Thought 或 ReAct）用于将复杂目标分解为步骤，并决定何时思考以及何时使用工具。这一层还负责赋予智能体"记忆"的能力

* 署（“身体和腿”）：在笔记本电脑上构建代理对于原型设计是有效的，但生产部署才是使其成为可靠且可访问服务的关键。这涉及将代理部署在安全、可扩展的服务器上，并与其监控、日志记录和管理等关键生产服务集成。一旦部署完成，用户可以通过图形界面访问代理，其他代理可以通过代理到代理（A2A）API 以编程方式访问

构建生成式 AI 代理是一种解决任务的新方法。传统开发者如同"砌砖工"，精确定义每个逻辑步骤。相比之下，代理开发者更像导演。你不必为每个动作编写显式代码，而是设置场景（指导指令和提示），选择演员（工具和 API），并提供必要背景（数据）。主要任务变成引导这个自主"演员"完成预期表现。

大语言模型能做任何事的能力，使其难以可靠且完美地执行特定任务。我们过去称之为"提示工程"，现在称之为"上下文工程"，是引导大语言模型生成所需输出的方法。对于每次调用大语言模型，我们输入指令、事实、可调用的工具、示例、会话历史、用户资料等——用恰到好处的信息填满上下文窗口以获得所需输出。代理是管理大语言模型输入以完成工作的软件。

当问题出现时，调试变得至关重要。"Agent Ops"本质上重新定义了测量、分析和系统优化的熟悉循环。通过跟踪和日志，你可以监控代理的"思维过程"，以识别与预期执行路径的偏差。随着模型的演进和框架的改进，开发者的角色是提供关键要素：领域专业知识、明确的个性特征，以及与完成实际任务所必需的工具的无缝集成。必须牢记的是，全面的评估和评估往往比初始提示的影响力更大

本质上，智能体是一个专注于上下文窗口管理的系统。它是一个不断循环的过程，包括收集上下文、提示模型、观察结果，然后为下一步重新组装上下文。上下文可能包括系统指令、用户输入、会话历史、长期记忆、来自权威来源的背景知识、可使用的工具以及已调用的工具结果。这种对模型注意力的复杂管理使其推理能力能够解决新情况并达成目标

### The Agentic Problem-Solving Process 代理式问题解决过程

1. 获取任务：该过程由一个特定的、高级别的目标启动。这个任务由用户提供
    - （例如，“为我团队的即将到来的会议安排旅行”）或由自动触发器提供（例如，“一个新的高优先级客户工单已到达”）
2. 扫描场景：智能体感知其环境以收集上下文。这涉及编排层访问其可用资源：“用户的请求说了什么？”“我的术语记忆中有什么信息？我已经尝试过完成这个任务吗？用户上周给我过指导吗？”“我能从我的工具中访问什么，比如日历、数据库或 API？”
3. 思考过程：这是智能体的核心“思考”循环，由推理模型驱动。智能体分析任务（步骤 1）相对于场景（步骤 2）并制定计划。这不是一个单一的想法，而通常是推理链：“要预订旅行，我首先需要知道团队中有谁。我将使用 get_team_roster 工具。然后我需要通过 calendar_api 检查他们的可用性。”
4. 采取行动：编排层执行计划的具体第一步。它选择并调用合适的工具——调用 API、运行代码函数或查询数据库。这是智能体在自身内部推理之外作用于世界的行为。
5. 观察与迭代：智能体观察其行动的结果。get_team_roster 工具返回一个包含五个名字的列表。这些新信息被添加到智能体的上下文或“记忆”中。然后循环重复，回到步骤 3：“现在我已经有了名单，下一步是检查这五个人的日程。我将使用 calendar_api。”

## A Taxonomy of Agentic Systems 代理系统的分类
### Level 0：核心推理系统

在拥有一个智能体之前，我们必须从其最基本的形式开始，即推理引擎本身。在这种配置下，一个语言模型（LM）独立运行，仅根据其庞大的预训练知识进行响应，没有任何工具、记忆或与实时环境的交互。

它的优势在于广泛的训练，使其能够深入解释既定概念，并规划如何以深度解决一个问题。代价是完全没有实时意识；它在功能上对训练数据之外的任何事件或事实都是“盲”的。

### Level 1: The Connected Problem-Solver

在这个级别上，推理引擎通过连接并利用外部工具——我们架构中的"手"组件，成为一个功能性的代理

这种与世界互动的基本能力——无论是使用搜索工具获取比分、使用金融 API 获取实时股价，还是通过检索增强生成（RAG）访问数据库——是第一级智能体的核心能力

### Level 2: The Strategic Problem-Solver

第二级标志着能力的显著扩展，从执行简单任务转变为战略性地规划复杂的多部分目标。这里出现的关键技能是上下文工程：智能体主动选择、打包和管理其计划每一步最相关信息的能力

智能体的准确性取决于专注、高质量的上下文。上下文工程通过精选模型的有限注意力来防止过载，并确保高效性能。

### Level 3: The Collaborative Multi-Agent System

最高层面上，范式完全转变。我们不再构建一个单一、全能的"超级代理"，而是转向一个"专家团队"协同工作的模式

在这里，代理将其他代理视为工具

### Level 4：自进化系统

第四级代表了从委托到自主创造和适应的巨大飞跃。在这个级别上，一个智能体系统可以识别自身能力的不足，并动态地创建新的工具甚至新的智能体来弥补这些不足。它从使用固定的资源集转变为主动扩展这些资源。

例子，负责“Solaris”发布的“项目经理”代理，可能会意识到需要监控社交媒体情绪，但它的团队里没有这样的工具或代理。

1. 思考（元推理）：“我必须追踪‘Solaris’的社交媒体热度，但我缺乏这个能力。”
2. . 行动（自主创建）：它不会失败，而是调用一个高级的 AgentCreator 工具，并赋予它一个新的任务：“构建一个新代理，用于监控社交媒体中的关键词‘Solaris 耳机’，执行情感分析，并每日报告总结。”
3. 观察：一个新的、专业的 SentimentAnalysisAgent 被创建、测试，并即时加入团队，准备为原任务做出贡献。

这种自主性，即系统可以动态扩展自身能力，将一个智能体团队转变为一个真正学习和进化的组织。

## 核心代理架构：模型、工具和编排

### Model: The “Brain” of your AI Agent

LM是Agent的推理核心，但仅靠基准分数去选择是导致失败的可能原因，一个Agent在生产环境中的成功很少由通用的学术基准决定。

现实中更需要的是具备卓越的推理能力来应对复杂的多步骤问题，以及可靠的工具使用能力来与世界互动的模型

要做好这一点，首先定义业务问题，然后测试模型与直接映射到该结果的指标。最好的模型是那个在质量、速度和价格上最适合你特定任务的模型

可以选择多个模型，组成一个“专家团队”。“你不能用大锤砸核桃”。一个稳健的代理架构可能会使用像 Gemini 2.5 Pro 这样的前沿模型来承担初始规划和复杂推理的重任，但随后将简单的、高容量的任务——比如分类用户意图或总结文本——智能地路由到一个更快更具有成本效益的模型，如 Gemini 2.5 Flash。模型路由可能是自动的或硬编码的，但它是优化性能和成本的关键策略

### Tools: The "Hands" of your AI Agent

一个强大的工具接口是一个三部分循环：定义工具能做什么，调用它，以及观察结果。

#### 获取信息：与现实相结合

最基础的工具是获取最新信息的能力

索增强生成（RAG）为智能体提供了一张“借书卡”，可以查询外部知识库，这些知识库通常存储在向量数据库或知识图谱中

#### 执行操作：改变世界

代理的真正力量在于它们从读取信息转变为主动执行任务。通过将现有的 API 和代码函数包装成工具，代理可以发送电子邮件、安排会议或更新 ServiceNow 中的客户记录。对于更动态的任务，代理可以即时编写和执行代码。在一个安全的沙盒中，它可以生成一个 SQL 查询或一个 Python 脚本来解决复杂问题或执行计算，将其从一个知识型助手转变为一个自主的行动者。

#### 函数调用：将工具连接到您的智能体

MCP 

### The Orchestration Layer   编排层

它是运行"思考、行动、观察"循环的引擎，是管理智能体行为的有限状态机，也是开发者精心设计的逻辑得以实现的地方

#### 核心设计

第一个架构决策是确定代理的自主程度：确定性 or 自适应
第二个是实施方法：低代码 or 高代码

#### 使用领域知识和角色进行指导

在这个框架中，开发者最强大的工具是向代理提供领域知识和独特的角色设定

####  添加上下文

代理的“记忆”在运行时被编排到语言模型的上下文窗口中

- 短期记忆它跟踪正在进行的循环中的（动作，观察）对序列，为模型提供立即的上下文，以便决定下一步做什么。这可以抽象为状态、工件、会话或线程等形式。
- 长期记忆提供跨会话的持久性
    - 从架构上看，这几乎总是通过另一个专用工具实现——一个连接到向量数据库或搜索引擎的检索增强生成（RAG）系统。编排器赋予代理预取和主动查询自身历史的能力，使其能够“记住”用户的偏好或几周前类似任务的结果，从而实现真正个性化和持续性的体验

### 多智能体系统与设计模式

可参考：https://cloud.google.com/architecture/choose-design-pattern-agentic-ai-system?hl=zh-cn#iterative-refinement-pattern

![](/assert/agent_iterative_refinement.jpg)

### 代理部署和服务

Google Vertex AI Agent Engine: https://docs.cloud.google.com/agent-builder/agent-engine/overview

![](/assert/agent-engine.png)

### Agent Ops

资料：https://medium.com/google-cloud/genai-in-production-mlops-or-genaiops-25691c9becd0

传统软件单元测试可以简单地断言输出 == 预期；但当智能体的响应设计为概率性时，这种方式就不适用了。此外，由于语言复杂，通常需要使用大语言模型来评估“质量”——即智能体的响应是否做到了它应该做的所有事情，没有做它不应该做的事情，并且语气得当。

![](/assert/agent_ops.webp)

- 衡量重要指标：像 A/B 实验一样监测成功
    - 这些指标应该超越技术正确性，并衡量实际影响：目标完成率、用户满意度评分、任务延迟时间、每次交互的运营成本，以及——最重要的是——对业务目标（如收入、转化率或客户留存率）的影响
- 质量而非合格/不合格：使用语言模型裁判
- 指标驱动开发：部署的可行与否
- 使用 OpenTelemetry 跟踪进行调试：回答"为什么？"
    - OpenTelemetry 跟踪记录是代理整个执行路径（轨迹）的高保真、逐步记录，允许你调试代理的步骤
    - 通过跟踪，你可以看到发送给模型的精确提示、模型的内部推理（如果可用）、它选择调用的具体工具、为该工具生成的精确参数，以及作为观察结果返回的原始数据
- 珍惜人类反馈：指导您的自动化

### Agent Interoperability   代理互操作性

#### Agents and Humans   智能体与人类

智能体与人类的交互最常见的形式是通过用户界面。、HITL的交互模式包括意图细化、目标扩展、确认和澄清请求。

人类互动并不仅限于屏幕和键盘。高级智能体正在打破文本障碍，进入实时、多模态的交流，通过“实时模式”创造更自然、更类似人类的连接。像 Gemini Live API31 这样的技术支持双向流式传输，允许用户与智能体交谈并打断它，就像在自然对话中那样

#### Agents and Agents   代理和代理

核心挑战有两个：
- 发现（我的智能体如何找到其他智能体并了解它们能做什么？）
- 通信（我们如何确保它们使用同一种语言？）

智能体间（A2A）协议是设计用来解决这个问题的开放标准。它充当智能体经济体的通用握手协议。A2A 允许任何智能体发布一个数字"名片"，称为智能体卡。这个简单的 JSON 文件宣传智能体的功能、其网络端点以及与它交互所需的凭证。这使得发现变得简单且标准化。与专注于解决交易请求的 MCP 不同，智能体间通信通常用于额外的解决问题

#### Agents and Money   代理与金钱

为了解锁真正的代理经济，我们需要新的标准，允许代理在代表用户时安全可靠地进行交易。

这一新兴领域远未成熟，但有两个关键协议正在铺平道路。代理支付协议（AP2）是一个开放协议，旨在成为代理式商业的最终语言。它通过引入加密签名数字"授权书"扩展了 A2A 等协议。这些授权书作为用户意图的可验证证明，为每笔交易创建不可否认的审计追踪。这使得代理能够在基于用户授权的全球范围内安全浏览、协商和交易。与之互补的是 x402，这是一个开放的互联网支付协议，它使用标准的 HTTP 402"需要付款"状态码。它支持无缝的机器对机器小额支付，允许代理按需支付 API 访问或数字内容等费用，而无需复杂的账户或订阅。这些协议共同构建了代理式网络的基础信任层

### 获取单个代理：信任权衡

当你创建第一个 AI 代理时，你立即面临一个基本矛盾：效用与安全之间的权衡。为了让代理变得有用，你必须赋予它权力——做出决策的自主权以及执行发送电子邮件或查询数据库等操作的工具。然而，你赋予的每一份权力都会引入相应的风险。主要的安全问题是无意的或有害的行为——即流氓行为

最佳实践是采用混合式纵深防御方法：
- 第一层由传统的确定性防护措施组成——一套硬编码的规则，这些规则作为模型推理之外的安防瓶颈。这可以是一个阻止任何超过 100 美元的购买的政策引擎，或者是在代理与外部 API 交互之前需要用户明确确认
- 第二层利用基于推理的防御机制，借助人工智能来保护人工智能。这包括训练模型使其更能抵抗攻击（对抗性训练），并采用更小、更专业的“安全分析模型”，这些模型如同安全分析师。这些模型可以在代理执行计划之前检查其计划，标记出潜在的高风险或违反政策的步骤以供审查

### 代理身份：一种新的主体类别

在传统安全模型中，存在可能使用 OAuth 或 SSO 的人类用户，以及使用 IAM 或服务账户的服务。代理增加了一个第三类主体。代理不仅仅是一段代码；它是一个自主的行动者，一种需要自己可验证身份的新类型主体。就像员工被发放身份卡一样，平台上的每个代理都必须被发放一个安全、可验证的“数字护照”。

### 从单个代理扩展到企业级车队

单一 AI 代理的成功生产是一项胜利。扩展到数百个代理则是一项架构挑战

#### 安全和隐私：加固智能代理前沿

企业级平台必须解决生成式 AI 特有的安全和隐私挑战，即使只有一个智能代理在运行也是如此。智能代理本身成为了一个新的攻击向量。恶意行为者可以尝试提示注入来劫持智能代理的指令，或数据中毒来破坏其用于训练或 RAG 的信息。此外，一个约束不当的智能代理可能会在其响应中无意泄露敏感客户数据或专有信息。

#### 代理治理：控制平面而非蔓延

随着代理及其工具在组织内扩散，它们创建了一个新的、复杂的交互网络和潜在漏洞，这一挑战通常被称为"代理蔓延"。管理这一情况需要超越保护单个代理，实施更高层次的建筑方法：一个中央网关作为所有代理活动的控制平面。

网关方法创建了那个控制系统，为所有代理交通设立了一个强制性的入口点，包括用户到代理的提示或 UI 交互、代理到工具的调用（通过 MCP）、代理到代理的协作（通过 A2A）以及直接对 LLM 发起的推理请求。通过位于这个关键交叉点，组织可以检查、路由、监控和管理每一次交互。


这个控制平面有两个主要且相互关联的功能：
1. 运行时策略执行：它充当实施安全的架构瓶颈。它处理身份验证（“我认识这个操作者吗？”）和授权（“他们有权这样做吗？”）。集中执行提供了一种“全局视图”，为每一笔交易创建通用日志、指标和跟踪。这将杂乱无章的不同代理和工作流转变为一个透明且可审计的系统
2. 集中治理：为了有效执行策略，网关需要一个真实来源。这由一个中央注册表提供——一个用于代理和工具的企业应用商店。该注册表允许开发人员发现和重用现有资源，防止重复工作，同时为管理员提供完整的清单。更重要的是，它为代理和工具提供了正式的生命周期，允许在发布前进行安全审查、版本控制，以及创建细粒度策略，这些策略规定了哪些业务单元可以访问哪些代理。

#### 成本与可靠性：基础设施基础

企业级代理必须既可靠又具有成本效益。一个经常失败或提供缓慢结果的代理会产生负的投资回报率。相反，一个过昂贵的代理无法扩展以满足业务需求。底层基础设施必须设计成能够管理这种权衡，安全地，并符合监管和数据主权合规要求

### 代理如何进化和学习

现实世界中的智能体在动态环境中运行，政策、技术和数据格式都在不断变化。如果没有适应能力，智能体的性能会随着时间的推移而下降——这个过程通常被称为“老化”

智能体通过经验和外部信号进行学习。这一学习过程由多种信息来源驱动：

1. 运行时经验：智能体从运行时产生的工件中学习，如会话日志、跟踪记录和内存，这些工件记录了成功、失败、工具交互和决策轨迹。关键的是，这还包括人在回路（HITL）反馈，它提供权威的纠正和指导。
2. 外部信号：学习也受到新的外部文档的驱动，例如更新的企业政策、公共监管指南或来自其他代理的批评。

最成功的适应技术分为两类：
1. 增强型上下文工程：系统持续优化其提示、少量示例以及从记忆中检索的信息。通过优化为大型语言模型（LM）提供的上下文，它增加了成功的可能性。
2. 工具优化与创建：代理的推理能力可以识别其能力的不足并采取行动弥补。这可能涉及获取新工具、即时创建新工具（例如，Python 脚本），或修改现有工具（例如，更新 API 架构）。

其他优化技术，如动态重新配置多代理设计模式或使用人类反馈强化学习（RLHF），是当前活跃的研究领域。

### Simulation and Agent Gym——下一个前沿

存在一个专门设计的平台，该平台通过先进的工具和功能，在离线过程中优化多代理系统，而这些工具和功能并不属于多代理运行时环境

1. 它不在执行路径上。它是一个独立的非生产平台，因此可以借助任何 LM 模型、离线工具、云应用等

2. 它提供了一个模拟环境，因此智能体可以在新数据上进行“练习”并学习。这个模拟环境非常适合进行“试错”，并且有很多优化路径

3. 它可以调用先进的合成数据生成器，这些生成器指导模拟尽可能逼真，并对代理进行压力测试（这可能包括先进的技术，例如红队演练、动态评估和一系列评论代理）
4. 优化工具箱并非固定不变，它可以采用新工具（通过 MCP 或 A2A 等开放协议），或在更高级的设置中——学习新概念并围绕这些概念制作工具

5. 最后，即使是像 Agent Gym 这样的构建，也可能无法克服某些边缘情况（由于企业中众所周知的“部落知识”问题）。在这些情况下，我们看到 Agent Gym 能够连接到领域专家的人类网络，并咨询他们关于正确结果集，以指导下一轮优化

## 高级代理的示例

### Google Co-Scientist   谷歌联合科学家

联合科学家是一个高级 AI 代理，设计为虚拟研究合作者，通过系统地探索复杂问题空间来加速科学发现。它使研究人员能够定义一个目标，将代理基于指定的公共和专有知识源进行定位，然后生成并评估一系列新颖的假设

![](/assert/agent_co_scientist_system.jpg)

将系统视为一个研究项目经理。AI 首先从一个广泛的研究目标开始，创建一个详细的项目计划。一个"监督者"代理随后充当项目经理的角色，将任务分配给一个由专业代理组成的团队，并分配计算能力等资源。这种结构确保项目可以轻松扩展，并且随着团队朝着最终目标努力工作，团队的方法会不断改进。

![](/assert/agent_co_scientist_system_2.jpg)

### AlphaEvolve Agent

一个用于发现和优化数学与计算机科学中复杂问题算法的人工智能智能体。

AlphaEvolve 通过结合我们 Gemini 语言模型的创造性代码生成与自动化评估系统来工作。它使用进化过程：人工智能生成潜在解决方案，评估器对其进行评分，最有潜力的想法被用作下一代代码的灵感来源。

这种方法已经带来了重大突破，包括：

- 提高 Google 数据中心的效率、芯片设计和人工智能训练的效率。 • 发现更快的矩阵乘法算法。
- 寻找解决开放数学问题的方案。

![](/assert/alpha_evolve.jpg)

AlphaEvolve 旨在实现人类与 AI 之间深度迭代合作。这种合作主要通过两种方式运作：
- 透明解决方案：AI 以人类可读的代码形式生成解决方案。这种透明性使用户能够理解逻辑、获取洞察、信任结果，并直接修改代码以满足需求。
- 专家指导：人类专业知识对于定义问题至关重要。用户通过优化评估指标和引导探索来指导 AI，这可防止系统利用问题定义中无意存在的漏洞。这种交互式循环确保最终解决方案既强大又实用

## Conclusion

生成式 AI 代理标志着关键性进化，将人工智能从被动的内容创作工具转变为主动、自主的问题解决伙伴

智能体分解为其三个核心组件：推理模型（"大脑"）、可执行工具（"双手"）和治理协调层（"神经系统"）。正是这些部分的完美集成，在持续的"思考、行动、观察"循环中，释放了智能体的真正潜力。通过将智能体系统分类——从一级连接型问题解决者到三级协作多智能体系统——架构师和产品领导者现在可以战略性地规划他们的目标，以匹配任务的复杂性


#### 相关链接

- MCP UI is a system of controlling UI via MCP tools https://mcpui.dev/.
- AG UI is a protocol of controlling UI via event passing and optionally shared state https://ag-ui.com/.
- A2UI is a protocol of generating UI via structured output and A2A message
passing https://github.com/google/A2UI.
- Guangya Liu, Sujay Solomon, March 2025 “AI Agent Observability - Evolving Standards and Best Practice”.
Available at: https://opentelemetry.io/blog/2025/ai-agent-observability/.